import sys
from pathlib import Path

import streamlit as st

from semantic.grammar_nn import analyze_text_nn
from text import normalize_text

_THIS = Path(__file__).resolve()
_ROOT = _THIS.parent.parent
if str(_ROOT) not in sys.path:
    sys.path.insert(0, str(_ROOT))


st.title('üìù –°–µ–º–∞–Ω—Ç–∏–∫–∞ –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞')
st.caption(
    '–î–≤–∞ —Ä–µ–∂–∏–º–∞: 1) –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ (SPO, –ø–∞–¥–µ–∂–∏, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ) ‚Äî –±–µ–∑ —ç—Ç–∞–ª–æ–Ω–∞; 2) –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å ‚Äî –ø–æ —ç—Ç–∞–ª–æ–Ω—É/–∫—Ä–∏—Ç–µ—Ä–∏—è–º.'
)
tab1, tab2 = st.tabs(['üî§ –ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ (SPO)', 'üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å'])
with tab1:
    st.subheader('–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    user_text = st.text_area(
        '–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞',
        height=220,
        key='grammar_text',
        placeholder='–í—Å—Ç–∞–≤—å—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º S‚ÄìP‚ÄìO, –ø–∞–¥–µ–∂–∞–º, –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–º –∏ –Ω–∞—Ä–µ—á–∏—è–º.',
    )
    with st.expander('‚öôÔ∏è –û–ø—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏', expanded=False):
        allow_ell = st.checkbox(
            '–†–∞–∑—Ä–µ—à–∞—Ç—å —ç–ª–ª–∏–ø—Å–∏—Å —Å—É–±—ä–µ–∫—Ç–∞ (–ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å S –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)',
            value=False,
            key='allow_ell',
        )
        lesson_items_str = st.text_area(
            '–ú–∞—Ç–µ—Ä–∏–∞–ª —É—Ä–æ–∫–∞ (–ª–µ–º–º—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)',
            placeholder='–Ω–∞–ø—Ä–∏–º–µ—Ä: —á–∏—Ç–∞—Ç—å, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π, –±—ã—Å—Ç—Ä–æ, —Å—Ç—É–¥–µ–Ω—Ç, –∫–Ω–∏–≥–∞',
            height=80,
            key='lesson_items_str',
        )
        lesson_items = (
            [x.strip().lower() for x in lesson_items_str.split(',') if x.strip()]
            if lesson_items_str
            else None
        )
    if st.button(
        'üöÄ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É', type='primary', use_container_width=True
    ):
        if not user_text.strip():
            st.warning('–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç.')
        else:
            norm = normalize_text(user_text)
            st.subheader('–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è')
            st.write(norm)
            try:
                report = analyze_text_nn(
                    norm, lesson_items=lesson_items, allow_subject_ellipsis=allow_ell
                )
                st.subheader('üèÅ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ')
                st.metric('–û–±—â–∏–π –±–∞–ª–ª', f'{report["score"]:.1f} / 100')
                st.markdown('#### –°–≤–æ–¥–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏')
                cols = st.columns(3)
                agg = report['aggregates']
                with cols[0]:
                    st.metric('S-P-O –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç', f'{agg["spo_presence"]:.1f}')
                    st.metric('–°—É–±—ä–µ–∫—Ç –≤ –ò.–ø.', f'{agg["subject_case_ok"]:.1f}')
                with cols[1]:
                    st.metric('–§–æ—Ä–º–∞ –ø—Ä–µ–¥–∏–∫–∞—Ç–∞', f'{agg["predicate_form_ok"]:.1f}')
                    st.metric('–ü–∞–¥–µ–∂ –æ–±—ä–µ–∫—Ç–∞', f'{agg["object_case_ok"]:.1f}')
                with cols[2]:
                    st.metric('–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–ª.', f'{agg["adj_agreement_ok"]:.1f}')
                    st.metric('–ü–æ–∑–∏—Ü–∏—è –Ω–∞—Ä–µ—á–∏–π', f'{agg["adv_position_ok"]:.1f}')
                if report.get('lesson_items_used'):
                    st.metric(
                        '–ú–∞—Ç–µ—Ä–∏–∞–ª —É—Ä–æ–∫–∞ (–±–∞–ª–ª)', f'{agg["lesson_usage_score"]:.1f}'
                    )
                    st.caption(
                        '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏–∑ —Å–ø–∏—Å–∫–∞: '
                        + ', '.join(report['lesson_items_used'])
                    )
                st.markdown('#### –î–µ—Ç–∞–ª—å–Ω–æ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º')
                import pandas as pd

                rows = []
                for s in report['sentences']:
                    checks = s['checks']
                    rows.append(
                        {
                            '–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ': s['sentence'],
                            '–°—É–±—ä–µ–∫—Ç': s['subject'] or '‚Äî',
                            '–ü—Ä–µ–¥–∏–∫–∞—Ç': s['predicate'] or '‚Äî',
                            '–û–±—ä–µ–∫—Ç': s['object'] or '‚Äî',
                            'SPO': '‚úì' if checks['spo_presence'] else '‚úó',
                            'Subj –ò.–ø.': '‚úì' if checks['subject_case_ok'] else '‚úó',
                            '–ü—Ä–µ–¥–∏–∫–∞—Ç –æ–∫': '‚úì' if checks['predicate_form_ok'] else '‚úó',
                            'Obj –ø–∞–¥–µ–∂': '‚úì' if checks['object_case_ok'] else '‚úó',
                            '–ü—Ä–∏–ª. —Å–æ–≥–ª–∞—Å.': '‚úì' if checks['adj_agreement_ok'] else '‚úó',
                            '–ù–∞—Ä–µ—á. –ø–æ–∑–∏—Ü–∏—è': '‚úì' if checks['adv_position_ok'] else '‚úó',
                            '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏': ' ‚Ä¢ '.join(s['suggestions']),
                        }
                    )
                df = pd.DataFrame(rows)
                st.dataframe(df, use_container_width=True, hide_index=True)
                st.markdown(
                    '> –†–∞–∑–±–æ—Ä –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º UD (Stanza): —Ä–æ–ª–∏ S/P/O, –ø–∞–¥–µ–∂–∏, amod/advmod, –ø—Ä–µ–¥–ª–æ–≥–∏ –∏ –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –±–µ–∑ ¬´—Å–ª–æ–≤–∞—Ä–∏ –ø–æ–¥ –∫–∞–∂–¥—ã–π –≥–ª–∞–≥–æ–ª¬ª.'
                )
            except RuntimeError as e:
                st.error(f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}')
                st.info(
                    '–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Stanza –∏ –º–æ–¥–µ–ª–∏ —Ä—É—Å—Å–∫–æ–≥–æ: `pip install stanza` –∑–∞—Ç–µ–º `python -c "import stanza; stanza.download(\'ru\')"`.'
                )
with tab2:
    st.subheader('–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    user_text_sem = st.text_area('–¢–µ–∫—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏', height=180, key='sem_text')
    reference = st.text_area(
        '–≠—Ç–∞–ª–æ–Ω/–∫—Ä–∏—Ç–µ—Ä–∏–∏ (–¥–ª—è —ç—Ç–æ–≥–æ —Ä–µ–∂–∏–º–∞)',
        height=120,
        placeholder='–û–ø–∏—à–∏—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç, –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —ç—Ç–∞–ª–æ–Ω.',
        key='sem_ref',
    )
    st.markdown('---')
    st.subheader('üß† –ü—Ä–æ–≤–∞–π–¥–µ—Ä –∏ –∑–∞–ø—É—Å–∫')
    provider = st.selectbox(
        '–ü—Ä–æ–≤–∞–π–¥–µ—Ä:',
        ['local-sbert', 'openai', 'hf-api'],
        help="'local-sbert' ‚Äî –ª–æ–∫–∞–ª—å–Ω–æ; 'openai' –∏ 'hf-api' ‚Äî —Ç—Ä–µ–±—É—é—Ç –∫–ª—é—á–∏ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.",
    )
    run_sem = st.button('üöÄ –û—Ü–µ–Ω–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–ª–∏–∑–æ—Å—Ç—å', use_container_width=True)
    if run_sem:
        if not user_text_sem.strip():
            st.warning('–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç.')
        else:
            try:
                from semantic.evaluator import SemanticEvaluator

                ev = SemanticEvaluator(provider=provider)
                res = ev.evaluate(
                    user_text_sem, reference=reference or None, criteria=None
                )
                st.metric('–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –±–∞–ª–ª', f'{res.score:.1f} / 100')
                st.caption(f'–ü—Ä–æ–≤–∞–π–¥–µ—Ä: {res.provider}')
                st.json(res.details)
                if isinstance(res.details, dict) and 'error' in res.details:
                    err = str(res.details['error']).lower()
                    if 'reference_empty' in err:
                        st.info(
                            "–î–ª—è —ç—Ç–æ–≥–æ —Ä–µ–∂–∏–º–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ '–≠—Ç–∞–ª–æ–Ω/–∫—Ä–∏—Ç–µ—Ä–∏–∏'. –ï—Å–ª–∏ —ç—Ç–∞–ª–æ–Ω –Ω–µ –Ω—É–∂–µ–Ω ‚Äî –ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –≤–∫–ª–∞–¥–∫–æ–π '–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ (SPO)'."
                        )
                    if 'openai' in err and 'module' in err:
                        st.info('–ü–æ—Ö–æ–∂–µ, –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç: `pip install openai`')
                    if 'sentence_transformers' in err:
                        st.info(
                            '–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: `pip install sentence-transformers` (–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ `pip install torch --index-url https://download.pytorch.org/whl/cpu`)'
                        )
                    if 'hf_api_token' in err or 'hf_api' in err:
                        st.info(
                            '–ó–∞–¥–∞–π—Ç–µ —Ç–æ–∫–µ–Ω HuggingFace: `$env:HF_API_TOKEN="hf_xxx"` –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ Streamlit –∏–∑ —Ç–æ–π –∂–µ —Å–µ—Å—Å–∏–∏.'
                        )
            except Exception as e:
                st.error(f'–ü—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}')
                st.info(
                    '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª `semantic/evaluator.py` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.'
                )
